# Tooth Image Classification â€“ Full Project README

This README provides a complete, structured documentation of your **Tooth Appearance Classification Project**, based entirely on your final experimental report and pipeline description.

---

## ğŸ“Œ 1. Project Overview

This project classifies intraoral dental photographs into **five orthodontic viewpoints**:

* **center** â€“ Frontal view
* **up** â€“ Upper occlusal view
* **down** â€“ Lower occlusal view
* **left** â€“ Left lateral view
* **right** â€“ Right lateral view

The goal is to determine the best model, resolution, and hyperparameter setup for robust clinical image classification.

---

## ğŸ“ 2. Dataset Description

* Images are organized **patientâ€‘wise**.
* Each patient folder includes 5 standard orthodontic viewpoints.
* Images vary in:

  * illumination
  * device type
  * angle and orientation
  * presence of orthodontic appliances

### âœ… Data Leakage Prevention

Splitting is done **per patient**, ensuring no patient appears in both training and testing.

---

## ğŸ› ï¸ 3. Preprocessing & Data Augmentation

### **3.1 Standard Preprocessing (all datasets)**

* Resize â†’ *(64, 128, 256, 512 depending on experiment)*
* Convert to RGB
* Convert to tensor
* Normalize using ImageNet means/std

### **3.2 Training Data Augmentation**

| Augmentation       | Value                               |
| ------------------ | ----------------------------------- |
| Rotation           | Â±45Â°                                |
| Affine Translation | Â±10%                                |
| Affine Scale       | Â±10%                                |
| ColorJitter        | Â±30% brightness/contrast/saturation |
| Vertical Flip      | p = 0.5                             |
| Resize             | 64â€“512 px                           |

Vertical flip was implemented **inside the Dataset class**, ensuring it is applied only to training samples.

---

## ğŸ“¦ 4. Dataset Class Functions

Your custom Dataset class performs:

* Image loading
* Label mapping
* Augmentation (training only)
* Transform selection based on split
* Returns `(image_tensor, label)`

---

## ğŸ§  5. Algorithms Used

Two versions of **ResNetâ€‘18** were evaluated:

### **5.1 Pretrained ResNetâ€‘18**

* ImageNet pretrained
* FC replaced with 5â€‘class output
* Best accuracy
* Selected for deployment

### **5.2 ResNetâ€‘18 (Scratch)**

* Same architecture, random initialization
* Required higher LR
* Underperformed vs pretrained

---

## ğŸ”¬ 6. Experimental Pipeline

Experiments were conducted in **three phases**:

### **Phase 1 â€” Hyperparameter Search (fixed resolution: 256Ã—256)**

Goal: Find best LR, Weight Decay, Batch Size.

### **Phase 2 â€” Resolution Search**

Resolutions tested:

* 64Ã—64
* 128Ã—128
* 224Ã—224
* 256Ã—256
* 512Ã—512
* 224Ã—224 (no augmentation)

### **Phase 3 â€” Final Training**

Train the final model using:

* Best params from Phase 1
* Best resolution from Phase 2
* 15 epochs

---

## ğŸ“Š 7. Hyperparameter Search Results

Below is the full **hyperparameter search table** reproduced exactly as in the document îˆ€fileciteîˆ‚turn1file0îˆ:

### **Table 1 â€” Hyperparameter Search Summary (Resolution = 256Ã—256)**

| **File Name**                                            | **Val Acc (%)** | **LR** | **WD** | **BS** | **Result**   |
| -------------------------------------------------------- | --------------- | ------ | ------ | ------ | ------------ |
| resnet18_pretrained_lr0.0001_wd1e-05_fold1_256.xlsx      | 92.56           | 1e-4   | 1e-5   | 16     | Best overall |
| resnet18_pretrained_lr0.0002_wd1e-05_bs8_fold1_256.xlsx  | 91.16           | 2e-4   | 1e-5   | 8      | Good         |
| resnet18_pretrained_lr1e-05_wd0.0001_bs8_fold1_256.xlsx  | 90.70           | 1e-5   | 1e-4   | 8      | Underfitting |
| resnet18_pretrained_lr0.0001_wd1e-05_bs8_fold1_256.xlsx  | 90.23           | 1e-4   | 1e-5   | 8      | Stable       |
| resnet18_pretrained_lr0.0002_wd1e-05_bs32_fold1_256.xlsx | 90.23           | 2e-4   | 1e-5   | 32     | Fluctuating  |
| resnet18_pretrained_lr1e-05_wd0.0001_fold1_256.xlsx      | 88.84           | 1e-5   | 1e-4   | 16     | Too slow     |
| resnet18_pretrained_lr0.0001_wd1e-05_bs32_fold1_256.xlsx | 88.84           | 1e-4   | 1e-5   | 32     | Unstable     |
| resnet18_pretrained_lr1e-05_wd0.0001_bs32_fold1_256.xlsx | 88.37           | 1e-5   | 1e-4   | 32     | Worst        |

### **Best Hyperparameter Combination**

| **LR**                              | **Weight Decay** | **Batch Size** | **Image Size** | **Model**            |           |
| ----------------------------------- | ---------------- | -------------- | -------------- | -------------------- | --------- |
| 0.0001                              | 1e-5             | 16             | 256Ã—256        | Pretrained ResNet-18 | (Phase 1) |
| **Best performance** achieved with: |                  |                |                |                      |           |

| LR         | Weight Decay | Batch Size | Image Size  | Model                    |
| ---------- | ------------ | ---------- | ----------- | ------------------------ |
| **0.0001** | **1eâ€‘5**     | **16**     | **256Ã—256** | **Pretrained ResNetâ€‘18** |

This configuration gave the top validation accuracy.

---

## ğŸ–¼ï¸ 8. Resolution Search Results

The following table reproduces the full multi-resolution comparison from page 6â€“7 of the document îˆ€fileciteîˆ‚turn1file0îˆ:

### **Table 3 â€” Full Comparison: Pretrained vs Scratch Models (All Resolutions)**

| **Model Variant**                                   | **Resolution**| **Accuracy(%)** | **Precision (%)** | **Recall (%)** | **F1-Score (%)** | **Inference Time (sec)** |           |
| --------------------------------------------------- | -------------- | ---------------- | ----------------- | -------------- | ---------------- | ------------------------ | --------- |
| ResNet18 (pretrained)                               | 512Ã—512        | 87.91            | 91.48             | 87.91          | 86.89            | 0.08                     |           |
| ResNet18 (scratch)                                  | 512Ã—512        | 81.86            | 90.49             | 81.86          | 78.18            | 0.08                     |           |
| ResNet18 (pretrained)                               | 256Ã—256        | 90.70            | 91.97             | 90.70          | 90.44            | 0.07                     |           |
| ResNet18 (scratch)                                  | 256Ã—256        | 79.53            | 80.37             | 79.53          | 79.09            | 0.07                     |           |
| ResNet18 (pretrained)                               | 64Ã—64          | 86.05            | 86.39             | 86.05          | 85.86            | 0.09                     |           |
| ResNet18 (scratch)                                  | 64Ã—64          | 87.91            | 88.76             | 87.91          | 87.64            | 0.07                     |           |
| ResNet18 (pretrained)                               | 224Ã—224        | 100              | 100               | 100            | 100              | 0.08                     |           |
| ResNet18 (scratch)                                  | 224Ã—224        | 100              | 100               | 100            | 100              | 0.08                     |           |
| ResNet18 (pretrained)                               | 128Ã—128        | 82.79            | 85.48             | 82.79          | 83.22            | 0.07                     |           |
| ResNet18 (scratch)                                  | 128Ã—128        | 61.40            | 53.89             | 61.40          | 55.79            | 0.07                     | (Phase 2) |
| A complete comparison across all resolutions shows: |                |                  |                   |                |                  |                          |           |

* Pretrained > Scratch consistently
* 256Ã—256 is the optimal resolution
* 512Ã—512 offers no improvement and slower inference

**Top results:**

* Pretrained 256Ã—256 â†’ **90.70% accuracy**
* Scratch 256Ã—256 â†’ **79.53% accuracy**

The pretrained model is consistently superior.

---

## ğŸ† 9. Final Experiment (Phase 3)

Final training using best hyperparameters and best resolution.

### **Final Scores (256Ã—256)**

| Model                      | Accuracy   | Precision | Recall | F1â€‘Score | Inference Time (sec/img) |
| -------------------------- | ---------- | --------- | ------ | -------- | ------------------------ |
| **ResNetâ€‘18 (Pretrained)** | **92.09%** | 92.13%    | 92.09% | 92.09%   | 0.000624                 |
| ResNetâ€‘18 (Scratch)        | 91.16%     | 91.23%    | 91.16% | 91.05%   | 0.000623                 |

### **Interpretation**

* Pretrained model performs better **across all metrics**.
* Improvements:

  * +0.93% Accuracy
  * +0.90% F1â€‘score
  * +0.96% Precision
  * +0.93% Recall
* Inference time is identical.

### **Final Conclusion**

The best model is:

| Setting            | Value                                        |
| ------------------ | -------------------------------------------- |
| **Model**          | ResNetâ€‘18 (Pretrained)                       |
| **Resolution**     | 256Ã—256                                      |
| **Learning Rate**  | 0.0001                                       |
| **Weight Decay**   | 1eâ€‘5                                         |
| **Batch Size**     | 16                                           |
| **Epoch Strategy** | Best test accuracy checkpoint                |
| **Augmentations**  | Rotation, Affine, ColorJitter, Vertical Flip |

---

## ğŸš€ 10. Inference Usage

Run inference and optional renaming via:

```
python inference.py --patient <folder> --model <model_path> --rename_output <output_folder>
```

---

## ğŸ“‹ 11. Folder Structure (Recommended)

```
ToothClassificationProject/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ patient_1/
â”‚   â”œâ”€â”€ patient_2/
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ PythonScript/
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ imports.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ Models/
â”‚   â””â”€â”€ resnet18_pretrained_best_256.pth
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ confusion_matrices/
â”‚   â””â”€â”€ summaries/
â”‚
â””â”€â”€ README.md
```

